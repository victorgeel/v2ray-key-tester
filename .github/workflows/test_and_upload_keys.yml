name: Test V2Ray Keys and Upload to R2 & GitHub

on:
  schedule:
    - cron: '*/15 * * * *' # Runs at the start of every hour
  workflow_dispatch: # Allows manual triggering

jobs:
  test-and-upload:
    runs-on: ubuntu-latest
    steps:
      # 1. Checkout repository
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PAT }}
          persist-credentials: false

      # 2. Set up Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # 3. Install Python dependencies
      - name: Install Python dependencies
        run: pip install -r requirements.txt

      # 4. Run V2Ray Key Tester Script and Collect Working Keys
      - name: Run V2Ray Key Tester Script
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python test_v2ray_keys.py
          echo "Testing Complete. Working keys saved to 'working_subscription.txt'."

      # 5. Commit and Push Subscription Files to Repo
      - name: Commit and Push Subscription Files to Repo
        run: |
          SUB_DIR="subscription"
          WORKING_KEYS="working_subscription.txt"
          if [ ! -d "${SUB_DIR}" ]; then
            echo "Directory '${SUB_DIR}' not found. Skipping Git commit."
          else
            git config --global user.name 'github-actions[bot]'
            git config --global user.email 'github-actions[bot]@users.noreply.github.com'
            git add ${SUB_DIR}/* ${WORKING_KEYS}
            git commit -m "Update subscription files and working keys [skip ci]" || echo "No changes to commit."
            git remote set-url origin https://x-access-token:${{ secrets.PAT }}@github.com/${{ github.repository }}
            git push origin HEAD:${{ github.ref_name }}
          fi

      # 6. Install rclone
      - name: Install rclone
        run: |
          sudo apt-get update && sudo apt-get install -y rclone

      # 7. Configure rclone for Cloudflare R2
      - name: Configure rclone for Cloudflare R2
        env:
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
        run: |
          rclone config create R2 s3 \
            provider=Cloudflare \
            access_key_id=$R2_ACCESS_KEY_ID \
            secret_access_key=$R2_SECRET_ACCESS_KEY \
            endpoint=$R2_ENDPOINT \
            acl=public-read

      # 8. Sync working key files to R2 Bucket
      - name: Sync working key files to R2 Bucket
        env:
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
        run: |
          SYNC_DIR="subscription"
          WORKING_KEYS="working_subscription.txt"
          if [ -d "./${SYNC_DIR}" ]; then
            rclone sync ./${SYNC_DIR} R2:${R2_BUCKET_NAME}/ --progress --verbose > rclone.log 2>&1
          fi
          if [ -f "./${WORKING_KEYS}" ]; then
            rclone copy ./${WORKING_KEYS} R2:${R2_BUCKET_NAME}/ --progress --verbose >> rclone.log 2>&1
          fi

      # 9. Verify Rclone Log (Optional)
      - name: Verify Rclone Log
        run: |
          if [ -f "rclone.log" ]; then
            echo "Rclone log file exists."
          else
            echo "Rclone log file does not exist!"
          fi

      # 10. Upload Rclone Logs for Debugging (Optional)
      - name: Upload Rclone Logs
        uses: actions/upload-artifact@v4.6.2
        with:
          name: rclone-logs
          path: rclone.log
          if-no-files-found: warn

      # 11. Clean up output directory
      - name: Clean up output directory
        run: |
          CLEANUP_DIR="subscription"
          if [ -d "./${CLEANUP_DIR}" ]; then
            rm -rf ./${CLEANUP_DIR}
          fi
