# Workflow Name
name: Test V2Ray Keys and Upload to R2 & GitHub

on:
  schedule:
    - cron: '*/15 * * * *' # Runs every 15 minutes
  workflow_dispatch: # Allows manual triggering

jobs:
  test-and-upload:
    runs-on: ubuntu-latest
    steps:
      # 1. Repository Checkout
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PAT }}
          persist-credentials: false

      # 2. Cache Python dependencies
      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      # 3. Set up Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # 4. Install dependencies
      - name: Install Python dependencies
        run: pip install -r requirements.txt

      # 5. Run the Python script
      - name: Run V2Ray Key Tester Script
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: python test_v2ray_keys.py

      # 6. Upload logs for debugging
      - name: Upload logs for debugging
        uses: actions/upload-artifact@v3
        with:
          name: script-logs
          path: subscription/job-logs.txt

      # 7. Commit and Push Subscription Files
      - name: Commit and Push Subscription Files to Repo
        run: |
          SUB_DIR="subscription"
          if [ ! -d "${SUB_DIR}" ]; then
            echo "Directory '${SUB_DIR}' not found. Skipping Git commit."
          else
            git config --global user.name 'github-actions[bot]'
            git config --global user.email 'github-actions[bot]@users.noreply.github.com'
            git add ${SUB_DIR}/*
            git commit -m "Force update subscription files in ${SUB_DIR} [skip ci]" || echo "No changes to commit."
            git remote set-url origin https://x-access-token:${{ secrets.PAT }}@github.com/${{ github.repository }}
            git push origin HEAD:${{ github.ref_name }}
          fi

      # 8. Install Rclone with caching
      - name: Install rclone
        run: |
          sudo apt-get update && sudo apt-get install -y rclone

      # 9. Configure Rclone for Cloudflare R2
      - name: Configure rclone for Cloudflare R2
        env:
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
        run: |
          rclone config create R2 s3 \
            provider=Cloudflare \
            access_key_id=$R2_ACCESS_KEY_ID \
            secret_access_key=$R2_SECRET_ACCESS_KEY \
            endpoint=$R2_ENDPOINT \
            acl=public-read

      # 10. Sync to R2 Bucket
      - name: Sync working key files to R2 Bucket
        env:
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
        run: |
          SYNC_DIR="subscription"
          if [ -d "./${SYNC_DIR}" ]; then
            rclone sync ./${SYNC_DIR} R2:${R2_BUCKET_NAME}/ --progress --verbose
          else
            echo "Output directory '${SYNC_DIR}' not found. Skipping R2 sync."
          fi

      # 11. Clean up output directory
      - name: Clean up output directory
        run: |
          CLEANUP_DIR="subscription"
          if [ -d "./${CLEANUP_DIR}" ]; then
            rm -rf ./${CLEANUP_DIR}
          fi
